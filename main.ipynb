{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import math\n",
    "import random\n",
    "from copy import deepcopy\n",
    "import json\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "from models.matching import OptimalMatching\n",
    "from models.backbone import R2U_Net, NonMaxSuppression, DetectionBranch\n",
    "from utils.utils import scores_to_permutations, permutations_to_polygons\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Polygon\n",
    "from rasterio import features\n",
    "\n",
    "from skimage import io\n",
    "from skimage.transform import resize\n",
    "import cv2\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RoofTop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycocotools.coco import COCO\n",
    "from pathlib import Path\n",
    "import os\n",
    "from pycocotools import mask as cocomask\n",
    "\n",
    "\n",
    "def clean(indices):\n",
    "    cleaned_indices = {}\n",
    "    k = 0\n",
    "    for i, (x,y) in enumerate(indices[:-1]):\n",
    "        if (x,y) not in cleaned_indices:\n",
    "            cleaned_indices[(x,y)] = k\n",
    "            k +=1\n",
    "    \n",
    "    for k, v in cleaned_indices.items():\n",
    "        indices[v] = list(k)\n",
    "\n",
    "    indices = indices[:len(cleaned_indices)]\n",
    "    indices = np.append(indices, indices[0])\n",
    "    return indices.reshape(-1,2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def collate_fn(batch):\n",
    "    return tuple(zip(*batch))\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "class RoofTopImage (Dataset):\n",
    "    def __init__(self,\n",
    "                 s3_image_bucket,\n",
    "                 prefix, \n",
    "                 annotation_path, \n",
    "                 max_corner_points=256, \n",
    "                 img_size=320, \n",
    "                 batchsize = 0,\n",
    "                 prediction = False, \n",
    "                 prediction_file_path=None,\n",
    "                 load_type = 'train',\n",
    "                 cache_data = 'True',\n",
    "                 cache_path='../data'\n",
    "                ):\n",
    "        self.s3_image_bucket = s3_image_bucket\n",
    "        self.prefix = prefix\n",
    "        self.load_type = load_type\n",
    "        self.cache_data = cache_data\n",
    "        self.cache_path = cache_path\n",
    "\n",
    "        self.annotation_path = annotation_path\n",
    "        self.prediction = prediction\n",
    "        self.img_annotations = COCO(self.annotation_path)\n",
    "        self.segs = []\n",
    "        self.batchsize = batchsize\n",
    "        \n",
    "        if self.prediction:\n",
    "            print('Loading prediction data ...', prediction_file_path)\n",
    "            prediction_file = json.loads(open(prediction_file_path).read())\n",
    "            self.img_annotations = self.img_annotations.loadRes(prediction_file)\n",
    "        \n",
    "        self.cat_id = self.img_annotations.getCatIds()\n",
    "        self.img_ids = self.img_annotations.getImgIds(catIds= self.cat_id)\n",
    "        self.img_ids = random.sample(range(0, len(self.img_ids)), 10000)\n",
    "        \n",
    "\n",
    "                         \n",
    "        self.window_size = img_size\n",
    "        self.corner_points = max_corner_points\n",
    "\n",
    "        if self.cache_data:\n",
    "            Path(os.path.join(self.cache_path, self.load_type)).mkdir(parents=True, exist_ok=True)\n",
    "            \n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.img_ids)\n",
    "    \n",
    "    def __getitem__(self, indx):\n",
    "        idx = self.img_ids[indx]\n",
    "        img = self.img_annotations.loadImgs(idx)[0]\n",
    "        \n",
    "        img_path = os.path.join(os.path.join(self.cache_path,self.load_type), img['file_name'])\n",
    "        \n",
    "    \n",
    "\n",
    "        # image = io.imread(img_path)\n",
    "        # orig_img_size = image.shape[0]\n",
    "        # image = resize(image, (self.window_size, self.window_size, 3), anti_aliasing=True, preserve_range=True)\n",
    "        # image = torch.from_numpy(image).to(torch.float32)\n",
    "        # image = image.permute(2,0,1) / 255.0\n",
    "        \n",
    "        \n",
    "        ann_ids = self.img_annotations.getAnnIds(imgIds=idx)\n",
    "        coco_annotations = self.img_annotations.loadAnns(ann_ids)\n",
    "        \n",
    "\n",
    "        num_objs = len(coco_annotations)\n",
    "        random.shuffle(coco_annotations)\n",
    "\n",
    "        corner_mask = np.zeros((self.window_size, self.window_size))\n",
    "        mask = np.zeros((self.window_size, self.window_size))\n",
    "\n",
    "        gt_index = {}\n",
    "        k = 0\n",
    "        gt_indices = []\n",
    "        gt_permutation_matrix = np.zeros((self.corner_points, self.corner_points))\n",
    " \n",
    "        for i in range(num_objs):\n",
    "            skip = False\n",
    "            corner_points =  np.flip(np.array(coco_annotations[i]['segmentation'][0]).reshape(-1,2),1)\n",
    "            #indices = corner_points.round().astype('int64')\n",
    "            point_pair = corner_points/ (300/self.window_size)\n",
    "            indices = point_pair.round().astype('int64').clip(0, self.window_size - 1)\n",
    "            \n",
    "            indices = clean(indices)\n",
    "            if indices.shape[0]-1  < 3:\n",
    "                continue\n",
    "\n",
    "            if indices[0][0] != indices[-1][0] or indices[0][1] != indices[-1][1]:\n",
    "                continue\n",
    "\n",
    "            for x,y in indices[:-1]:\n",
    "                if (x,y) not in gt_index:\n",
    "                    gt_index[(x,y)] = k\n",
    "                    k+=1\n",
    "                else:\n",
    "                    #seen before\n",
    "                    skip = True\n",
    "                    break\n",
    "            if skip:\n",
    "                continue\n",
    "                \n",
    "            \n",
    "            corner_mask[indices[:-1][:,0], indices[:-1][:,1]] = 1\n",
    "            gt_indices.append(indices.tolist())\n",
    "            \n",
    "            rle = cocomask.frPyObjects(coco_annotations[i]['segmentation'],self.window_size,self.window_size)\n",
    "            m = cocomask.decode(rle).astype('float32')\n",
    "            m = m.reshape((self.window_size, self.window_size))\n",
    "            mask = mask + m.reshape((self.window_size, self.window_size))\n",
    "        \n",
    "        vertices = [v for polygon in gt_indices for v in polygon[:-1]]\n",
    "        num_vertices = 0\n",
    "       \n",
    "        for polygon in gt_indices: # take care of cases where gt_indices in empty\n",
    "            n = len(polygon)\n",
    "            num_vertices += n-1\n",
    "            # iterate through each vertex and its corresponding adjacent vertex\n",
    "            for i in range(n-1):\n",
    "                v1 = polygon[i]\n",
    "                v2 = polygon[(i + 1) % (n-1)]\n",
    "                gt_permutation_matrix[gt_index[tuple(v1)]][gt_index[tuple(v2)]] = 1 \n",
    "                \n",
    "        #vertices = np.array(vertices)\n",
    "        gt_permutation_matrix[range(num_vertices, self.corner_points), range(num_vertices, self.corner_points)] =1\n",
    "        #image_idx = torch.tensor([idx])\n",
    "       \n",
    "        return torch.from_numpy(gt_permutation_matrix), np.array(vertices), gt_index, torch.from_numpy(corner_mask), torch.from_numpy(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_BUCKET=\"sundial-geometric-roof-inference\"\n",
    "\n",
    "TRAIN_IMAGE_PREFIX= 'data/val/images'\n",
    "# VAL_IMAGE_PREFIX= 'data/val/images' \n",
    "\n",
    "\n",
    "TRAIN_ANNOTATION_PATH = 'data/train/annotation.json'\n",
    "# VAL_ANNOTATION_PATH = 'data/val/annotation.json'\n",
    "\n",
    "PREDICTION_PATH = 'raw_val_predictions.json'\n",
    "\n",
    "BATCH_SIZE = 6\n",
    "MAX_CORNER_POINTS = 256\n",
    "NUM_EPOCHS = 10\n",
    "INIT_LR = 0.001\n",
    "LAMBDA = 1000\n",
    "IMG_SIZE = 320\n",
    "BASE_OUTPUT = \"output\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "train_data = RoofTopImage(IMAGE_BUCKET,\n",
    "                          TRAIN_IMAGE_PREFIX,\n",
    "                          TRAIN_ANNOTATION_PATH,\n",
    "                          MAX_CORNER_POINTS, \n",
    "                          IMG_SIZE,\n",
    "                          BATCH_SIZE,\n",
    "                          load_type = 'train'\n",
    "                         )\n",
    "\n",
    "trainloader = DataLoader(train_data,\n",
    "                        batch_size=BATCH_SIZE,\n",
    "                        shuffle=True,\n",
    "                        num_workers=0,\n",
    "                        pin_memory=False,\n",
    "                        #prefetch_factor = BATCH_SIZE,\n",
    "                        drop_last=True,\n",
    "                        collate_fn=collate_fn\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_sync_nsm_points(nms_graph, vertices,gt_index): \n",
    "    B, N, D= nms_graph.shape #1,256,2\n",
    "    sorted_nsm_points = np.zeros((B,N,D), dtype=int)\n",
    "    nms_graph = nms_graph.detach().cpu().numpy()\n",
    "    \n",
    "    for b in range(B):\n",
    "        sorted_nsm = np.zeros((N,D), dtype=int)\n",
    "\n",
    "        #vertices = np.array([v for polygon in gt_indices[b] for v in polygon[:-1]])        \n",
    "        n = vertices[b].shape[0]\n",
    "        m = nms_graph[b].shape[0]\n",
    "    \n",
    "        distances = np.linalg.norm(vertices[b][:, None] - nms_graph[b], axis=2)\n",
    "        distances = distances.reshape(n*m, 1)\n",
    "        \n",
    "        distances = np.hstack((distances,np.repeat(vertices[b], m, axis=0),np.tile(nms_graph[b], (n, 1))))\n",
    "        sorted_distance = distances[np.argsort(distances[:,0])]\n",
    "        \n",
    "        # Sort distances by the first column (distance)\n",
    "        sorted_distances = distances[np.argsort(distances[:,0])]\n",
    "\n",
    "        cndd_used = set()\n",
    "        gt_used = set()\n",
    "        cndd_mapped = {tuple(cndd):0 for cndd in nms_graph[b]}\n",
    "       \n",
    "        for d_p in sorted_distances:\n",
    "            gt_p = tuple((d_p[1], d_p[2]))\n",
    "            cndd_p = tuple((d_p[3], d_p[4]))\n",
    "            if gt_p not in gt_used and cndd_p not in cndd_used:\n",
    "                #print('we have a match ..', gt_p ,'->', cndd_p, ' with distance of ', d_p[0])\n",
    "                sorted_nsm[gt_index[b][gt_p]]= list(cndd_p)\n",
    "                gt_used.add(gt_p)\n",
    "                cndd_used.add(cndd_p)\n",
    "                cndd_mapped[cndd_p] =1\n",
    "                                \n",
    "        restart_index = n\n",
    "        for k, v in cndd_mapped.items():\n",
    "            if v ==0:\n",
    "                sorted_nsm[restart_index] = list(k)   \n",
    "                restart_index +=1\n",
    "        sorted_nsm_points[b] = sorted_nsm \n",
    "    return torch.from_numpy(sorted_nsm_points).to(device)\n",
    "\n",
    "def prepare_gt_vertices(vertices):\n",
    "    B = len(vertices)\n",
    "    v_gt = torch.empty((BATCH_SIZE, MAX_CORNER_POINTS, 2), dtype=torch.float64)\n",
    "    for b in range(B):\n",
    "        gt_size = vertices[b].shape[0]\n",
    "        extra = torch.full((MAX_CORNER_POINTS - gt_size, 2), 0, dtype = torch.float64)\n",
    "        extra_gt = torch.cat((torch.from_numpy(vertices[b]), extra), dim=0).to(device)\n",
    "        v_gt[b] = extra_gt\n",
    "    return v_gt.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "permutation_matrix, vertices, gt_index, corner_mask, mask = next(iter(trainloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(permutation_matrix[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(mask[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(corner_mask[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corner_mask[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vertices[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vertices[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_nsm_points = sort_sync_nsm_points(nms_graph, vertices, gt_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepare_gt_vertices(vertices).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepare_gt_vertices(vertices)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.stack(permutation_matrix).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(20, 5))\n",
    "axes[0].imshow(corner_mask[0])\n",
    "axes[0].set_title(\"Corner Mask\")\n",
    "\n",
    "axes[1].imshow(mask[0])\n",
    "axes[1].set_title(\"Mask\")\n",
    "\n",
    "axes[2].imshow(permutation_matrix[0])\n",
    "axes[2].set_title(\"Permutation Matrix\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CrowdAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrowdAI(Dataset):\n",
    "\n",
    "    def __init__(self, images_directory, annotations_path):\n",
    "\n",
    "        self.IMAGES_DIRECTORY = images_directory\n",
    "        self.ANNOTATIONS_PATH = annotations_path\n",
    "        \n",
    "        self.window_size = 320\n",
    "        self.max_points = 256\n",
    "\n",
    "        # load annotation json\n",
    "        with open(self.ANNOTATIONS_PATH) as f:\n",
    "            self.annotations = json.load(f)\n",
    "        \n",
    "        self.images = pd.DataFrame(self.annotations['images'])[:4]\n",
    "        self.labels = pd.DataFrame(self.annotations['annotations'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def _create_permutation_matrix(self, segmentations, N=256):\n",
    "\n",
    "        permutation_matrix = torch.zeros((N, N), dtype=torch.uint8)\n",
    "\n",
    "        n = 0\n",
    "        for i, polygon in enumerate(segmentations):\n",
    "            for v, point in enumerate(polygon):\n",
    "                if v != len(polygon) - 1:\n",
    "                    permutation_matrix[n, n+1] = 1\n",
    "                else:\n",
    "                    permutation_matrix[n, n-v] = 1\n",
    "                n += 1\n",
    "        for i in range(n, N):\n",
    "            permutation_matrix[i, i] = 1\n",
    "\n",
    "        return permutation_matrix\n",
    "        \n",
    "\n",
    "\n",
    "    def _create_segmentation_mask(self, polygons, image_size):\n",
    "        mask = np.zeros((image_size, image_size), dtype=np.uint8)\n",
    "        for polygon in polygons:\n",
    "            cv2.fillPoly(mask, [polygon], 1)\n",
    "        return torch.tensor(mask, dtype=torch.uint8)\n",
    "\n",
    "\n",
    "\n",
    "    def _create_vertex_mask(self, polygons, image_shape=(320, 320)):\n",
    "        mask = torch.zeros(image_shape, dtype=torch.uint8)\n",
    "\n",
    "        for poly in polygons:\n",
    "            for p in poly:\n",
    "                mask[p[1], p[0]] = 1\n",
    "\n",
    "        return mask\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        image = io.imread(self.IMAGES_DIRECTORY + self.images['file_name'][idx])\n",
    "        image = resize(image, (self.window_size, self.window_size), anti_aliasing=True)\n",
    "        image = torch.from_numpy(image)\n",
    "        width, height = self.images['width'][idx], self.images['height'][idx]\n",
    "        ratio = self.window_size / max(width, height)\n",
    "\n",
    "\n",
    "\n",
    "        # Get the image ID\n",
    "        image_id = self.images['id'][idx]\n",
    "        # Get all annotations for this image\n",
    "        image_annotations = self.labels[self.labels['image_id'] == image_id]\n",
    "        # get all polygons for the image\n",
    "        segmentations = image_annotations['segmentation'].values\n",
    "        segmentations = [e[0] for e in segmentations]\n",
    "        for i, poly in enumerate(segmentations):\n",
    "            # rescale the polygon\n",
    "            poly = [int(e * ratio) for e in poly]\n",
    "            # out of bounds check\n",
    "            for j, e in enumerate(poly):\n",
    "                if j % 2 == 0:\n",
    "                    poly[j] = min(max(0, e), self.window_size - 1)\n",
    "                else:\n",
    "                    poly[j] = min(max(0, e), self.window_size - 1)\n",
    "            segmentations[i] = poly\n",
    "\n",
    "\n",
    "\n",
    "        # print(segmentations)\n",
    "        segmentations = [np.array(poly, dtype=int).reshape(-1, 2) for poly in segmentations] # convert a list of polygons to a list of numpy arrays of points\n",
    "        # print(segmentations)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        # create permutation matrix\n",
    "        permutation_matrix = self._create_permutation_matrix(segmentations, N=self.max_points)\n",
    "        # create vertex mask\n",
    "        vertex_mask = self._create_vertex_mask(segmentations, image_shape=(self.window_size, self.window_size))\n",
    "        # create segmentation mask\n",
    "        seg_mask = self._create_segmentation_mask(segmentations, image_size=self.window_size)\n",
    "        # print(torch.topk(torch.tensor(vertex_mask.flatten()), self.max_points))\n",
    "\n",
    "\n",
    "        segmentations = [torch.from_numpy(poly) for poly in segmentations]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        return image, vertex_mask, seg_mask, permutation_matrix, segmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    return tuple(zip(*batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate the dataloader\n",
    "batch_size = 2\n",
    "dataset = CrowdAI(images_directory='data/val/images/', annotations_path='data/val/annotation.json')\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=4, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image, gt_vertex_mask, gt_seg_mask, gt_permutation_matrix, gt_polygons = next(iter(dataloader))\n",
    "image, gt_vertex_mask, gt_seg_mask, gt_permutation_matrix = torch.stack(image), torch.stack(gt_vertex_mask), torch.stack(gt_seg_mask), torch.stack(gt_permutation_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Image: ', image.shape)\n",
    "print('Vertex: ', gt_vertex_mask.shape)\n",
    "print('Segmentation: ', gt_seg_mask.shape)\n",
    "print('Permutation: ', gt_permutation_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(gt_polygons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot all the masks and the images in the batch\n",
    "B = len(image)\n",
    "fig, axes = plt.subplots(B, 4, figsize=(21, 7*B))\n",
    "for i in range(B):\n",
    "    axes[i, 0].imshow(image[i])\n",
    "    axes[i, 1].imshow(gt_seg_mask[i])\n",
    "    axes[i, 2].imshow(gt_vertex_mask[i])\n",
    "    axes[i, 3].imshow(gt_permutation_matrix[i])\n",
    "\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot all the images, vertex masks, and scatter plots in the batch\n",
    "B = len(image)\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(B, 3, figsize=(21, 7*B))\n",
    "\n",
    "for i in range(B):\n",
    "    # Original image\n",
    "    axes[i, 0].imshow(image[i])\n",
    "    axes[i, 0].set_title(f'Original Image {i+1}')\n",
    "    axes[i, 0].axis('off')\n",
    "\n",
    "    # Vertex mask as image\n",
    "    axes[i, 1].imshow(gt_vertex_mask[i], cmap='viridis')\n",
    "    axes[i, 1].set_title(f'Vertex Mask {i+1}')\n",
    "    axes[i, 1].axis('off')\n",
    "\n",
    "    # Scatter plot of vertex mask on original image\n",
    "    axes[i, 2].imshow(image[i])\n",
    "    y, x = np.nonzero(gt_vertex_mask[i].numpy())\n",
    "    scatter = axes[i, 2].scatter(x, y, c=gt_vertex_mask[i].numpy()[y, x], s=20, alpha=0.5, cmap='Oranges_r')\n",
    "    axes[i, 2].set_title(f'Overlay {i+1}')\n",
    "    axes[i, 2].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vertex Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DetectionBranch(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DetectionBranch,self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(64, 64, kernel_size=1,stride=1,padding=0,bias=True),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, 1, kernel_size=1,stride=1,padding=0,bias=True)\n",
    "        )\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.conv(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class up_conv(nn.Module):\n",
    "    def __init__(self,ch_in,ch_out):\n",
    "        super(up_conv,self).__init__()\n",
    "        self.up = nn.Sequential(\n",
    "            nn.Upsample(scale_factor=2),\n",
    "            nn.Conv2d(ch_in,ch_out,kernel_size=3,stride=1,padding=1,bias=True),\n",
    "\t\t    nn.BatchNorm2d(ch_out),\n",
    "\t\t\tnn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.up(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class Recurrent_block(nn.Module):\n",
    "    def __init__(self,ch_out,t=2):\n",
    "        super(Recurrent_block,self).__init__()\n",
    "        self.t = t\n",
    "        self.ch_out = ch_out\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(ch_out,ch_out,kernel_size=3,stride=1,padding=1,bias=True),\n",
    "\t\t    nn.BatchNorm2d(ch_out),\n",
    "\t\t\tnn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self,x):\n",
    "        for i in range(self.t):\n",
    "\n",
    "            if i==0:\n",
    "                x1 = self.conv(x)\n",
    "            \n",
    "            x1 = self.conv(x+x1)\n",
    "        return x1\n",
    "\n",
    "        \n",
    "class RRCNN_block(nn.Module):\n",
    "    def __init__(self,ch_in,ch_out,t=2):\n",
    "        super(RRCNN_block,self).__init__()\n",
    "        self.RCNN = nn.Sequential(\n",
    "            Recurrent_block(ch_out,t=t),\n",
    "            Recurrent_block(ch_out,t=t)\n",
    "        )\n",
    "        self.Conv_1x1 = nn.Conv2d(ch_in,ch_out,kernel_size=1,stride=1,padding=0)\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.Conv_1x1(x)\n",
    "        x1 = self.RCNN(x)\n",
    "        return x+x1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Backbone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class R2U_Net(nn.Module):\n",
    "    def __init__(self,img_ch=3,t=1):\n",
    "        super(R2U_Net,self).__init__()\n",
    "        \n",
    "        self.Maxpool = nn.MaxPool2d(kernel_size=2,stride=2)\n",
    "        self.Upsample = nn.Upsample(scale_factor=2)\n",
    "\n",
    "        self.RRCNN1 = RRCNN_block(ch_in=img_ch,ch_out=64,t=t)\n",
    "        self.RRCNN2 = RRCNN_block(ch_in=64,ch_out=128,t=t)\n",
    "        self.RRCNN3 = RRCNN_block(ch_in=128,ch_out=256,t=t)\n",
    "        self.RRCNN4 = RRCNN_block(ch_in=256,ch_out=512,t=t)\n",
    "        self.RRCNN5 = RRCNN_block(ch_in=512,ch_out=1024,t=t)\n",
    "        \n",
    "        self.Up5 = up_conv(ch_in=1024,ch_out=512)\n",
    "        self.Up_RRCNN5 = RRCNN_block(ch_in=1024, ch_out=512,t=t)\n",
    "        \n",
    "        self.Up4 = up_conv(ch_in=512,ch_out=256)\n",
    "        self.Up_RRCNN4 = RRCNN_block(ch_in=512, ch_out=256,t=t)\n",
    "        \n",
    "        self.Up3 = up_conv(ch_in=256,ch_out=128)\n",
    "        self.Up_RRCNN3 = RRCNN_block(ch_in=256, ch_out=128,t=t)\n",
    "        \n",
    "        self.Up2 = up_conv(ch_in=128,ch_out=64)\n",
    "        self.Up_RRCNN2 = RRCNN_block(ch_in=128, ch_out=64,t=t)\n",
    "\n",
    "\n",
    "    def forward(self,x):\n",
    "        # encoding path\n",
    "        x1 = self.RRCNN1(x)\n",
    "\n",
    "        x2 = self.Maxpool(x1)\n",
    "        x2 = self.RRCNN2(x2)\n",
    "        \n",
    "        x3 = self.Maxpool(x2)\n",
    "        x3 = self.RRCNN3(x3)\n",
    "\n",
    "        x4 = self.Maxpool(x3)\n",
    "        x4 = self.RRCNN4(x4)\n",
    "\n",
    "        x5 = self.Maxpool(x4)\n",
    "        x5 = self.RRCNN5(x5)\n",
    "\n",
    "        # decoding + concat path\n",
    "        d5 = self.Up5(x5)\n",
    "        d5 = torch.cat((x4,d5),dim=1)\n",
    "        d5 = self.Up_RRCNN5(d5)\n",
    "        \n",
    "        d4 = self.Up4(d5)\n",
    "        d4 = torch.cat((x3,d4),dim=1)\n",
    "        d4 = self.Up_RRCNN4(d4)\n",
    "\n",
    "        d3 = self.Up3(d4)\n",
    "        d3 = torch.cat((x2,d3),dim=1)\n",
    "        d3 = self.Up_RRCNN3(d3)\n",
    "\n",
    "        d2 = self.Up2(d3)\n",
    "        d2 = torch.cat((x1,d2),dim=1)\n",
    "        d2 = self.Up_RRCNN2(d2)\n",
    "\n",
    "        return d2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This block is not diffrentiable\n",
    "\n",
    "class NonMaxSuppression(nn.Module):\n",
    "    def __init__(self, n_peaks=256):\n",
    "        super(NonMaxSuppression,self).__init__()\n",
    "        self.k = 3 # kernel\n",
    "        self.p = 1 # padding\n",
    "        self.s = 1 # stride\n",
    "        self.center_idx = self.k**2//2\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.unfold = nn.Unfold(kernel_size=self.k, padding=self.p, stride=self.s)\n",
    "        self.n_peaks = n_peaks\n",
    "\n",
    "    def sample_peaks(self, x):\n",
    "        B, _, H, W = x.shape\n",
    "        for b in range(B):\n",
    "            x_b = x[b,0]\n",
    "            idx = torch.topk(x_b.flatten(), self.n_peaks).indices\n",
    "            idx_i = torch.div(idx, W, rounding_mode='floor')\n",
    "            idx_j = idx % W\n",
    "            idx = torch.cat((idx_i.unsqueeze(1), idx_j.unsqueeze(1)), dim=1)\n",
    "            idx = idx.unsqueeze(0)\n",
    "\n",
    "            if b == 0:\n",
    "                graph = idx\n",
    "            else:\n",
    "                graph = torch.cat((graph, idx), dim=0)\n",
    "\n",
    "        return graph \n",
    "\n",
    "    def forward(self, feat):\n",
    "        B, C, H, W = feat.shape\n",
    "\n",
    "        x = self.sigmoid(feat)\n",
    "\n",
    "        # Prepare filter\n",
    "        f = self.unfold(x).view(B, self.k**2, H, W)\n",
    "        f = torch.argmax(f, dim=1).unsqueeze(1)\n",
    "        f = (f == self.center_idx).float()\n",
    "\n",
    "        # Apply filter\n",
    "        x = x * f\n",
    "\n",
    "        # Sample top peaks\n",
    "        graph = self.sample_peaks(x)\n",
    "        return x, graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MultiLayerPerceptron(channels: list, batch_norm=True):\n",
    "    n_layers = len(channels)\n",
    "\n",
    "    layers = []\n",
    "    for i in range(1, n_layers):\n",
    "        layers.append(nn.Conv1d(channels[i - 1], channels[i], kernel_size=1, bias=True))\n",
    "\n",
    "        if i < (n_layers - 1):\n",
    "            if batch_norm:\n",
    "                layers.append(nn.BatchNorm1d(channels[i]))\n",
    "            layers.append(nn.ReLU())\n",
    "\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "\n",
    "class Attention(nn.Module):\n",
    "\n",
    "    def __init__(self, n_heads: int, d_model: int):\n",
    "        super().__init__()\n",
    "        assert d_model % n_heads == 0\n",
    "        self.dim = d_model // n_heads\n",
    "        self.n_heads = n_heads\n",
    "        self.merge = nn.Conv1d(d_model, d_model, kernel_size=1)\n",
    "        self.proj = nn.ModuleList([deepcopy(self.merge) for _ in range(3)])\n",
    "\n",
    "    def forward(self, query, key, value):\n",
    "        b = query.size(0)\n",
    "        query, key, value = [l(x).view(b, self.dim, self.n_heads, -1)\n",
    "                             for l, x in zip(self.proj, (query, key, value))]\n",
    "\n",
    "        b, d, h, n = query.shape\n",
    "        scores = torch.einsum('bdhn,bdhm->bhnm', query, key) / d**.5\n",
    "        attn = torch.einsum('bhnm,bdhm->bdhn', torch.nn.functional.softmax(scores, dim=-1), value)\n",
    "\n",
    "        return self.merge(attn.contiguous().view(b, self.dim*self.n_heads, -1))\n",
    "\n",
    "\n",
    "class AttentionalPropagation(nn.Module):\n",
    "\n",
    "    def __init__(self, feature_dim: int, n_heads: int):\n",
    "        super().__init__()\n",
    "        self.attn = Attention(n_heads, feature_dim)\n",
    "        self.mlp = MultiLayerPerceptron([feature_dim*2, feature_dim*2, feature_dim])\n",
    "        nn.init.constant_(self.mlp[-1].bias, 0.0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        message = self.attn(x, x, x)\n",
    "        return self.mlp(torch.cat([x, message], dim=1))\n",
    "\n",
    "\n",
    "class AttentionalGNN(nn.Module):\n",
    "\n",
    "    def __init__(self, feature_dim: int, num_layers: int):\n",
    "        super().__init__()\n",
    "        self.conv_init = nn.Sequential(\n",
    "            nn.Conv1d(feature_dim + 2, feature_dim, kernel_size=1,stride=1,padding=0,bias=True),\n",
    "            nn.BatchNorm1d(feature_dim),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv1d(feature_dim, feature_dim, kernel_size=1,stride=1,padding=0,bias=True),\n",
    "            nn.BatchNorm1d(feature_dim),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv1d(feature_dim, feature_dim, kernel_size=1,stride=1,padding=0,bias=True)\n",
    "        )\n",
    "\n",
    "        self.layers = nn.ModuleList([\n",
    "            AttentionalPropagation(feature_dim, 4)\n",
    "            for _ in range(num_layers)])\n",
    "\n",
    "        self.conv_desc = nn.Sequential(\n",
    "            nn.Conv1d(feature_dim, feature_dim, kernel_size=1,stride=1,padding=0,bias=True),\n",
    "            nn.BatchNorm1d(feature_dim),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv1d(feature_dim, feature_dim, kernel_size=1,stride=1,padding=0,bias=True),\n",
    "            nn.BatchNorm1d(feature_dim),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "        self.conv_offset = nn.Sequential(\n",
    "            nn.Conv1d(feature_dim, feature_dim, kernel_size=1,stride=1,padding=0,bias=True),\n",
    "            nn.BatchNorm1d(feature_dim),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv1d(feature_dim, feature_dim, kernel_size=1,stride=1,padding=0,bias=True),\n",
    "            nn.BatchNorm1d(feature_dim),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv1d(feature_dim, 2, kernel_size=1,stride=1,padding=0,bias=True),\n",
    "            nn.Hardtanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, feat, graph):\n",
    "        graph = graph.permute(0,2,1)\n",
    "        feat = torch.cat((feat, graph), dim=1)\n",
    "        feat = self.conv_init(feat)\n",
    "\n",
    "        for layer in self.layers:\n",
    "            feat = feat + layer(feat)\n",
    "\n",
    "        desc = self.conv_desc(feat)\n",
    "        offset = self.conv_offset(feat).permute(0,2,1)\n",
    "        return desc, offset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimal Connection Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScoreNet(nn.Module):\n",
    "\n",
    "    def __init__(self, in_ch):\n",
    "        super().__init__()\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv1 = nn.Conv2d(in_ch, 256, kernel_size=1, stride=1, padding=0, bias=True)\n",
    "        self.bn1 = nn.BatchNorm2d(256)\n",
    "        self.conv2 = nn.Conv2d(256, 128, kernel_size=1, stride=1, padding=0, bias=True)\n",
    "        self.bn2 = nn.BatchNorm2d(128)\n",
    "        self.conv3 = nn.Conv2d(128, 64, kernel_size=1, stride=1, padding=0, bias=True)\n",
    "        self.bn3 = nn.BatchNorm2d(64)\n",
    "        self.conv4 = nn.Conv2d(64, 1, kernel_size=1, stride=1, padding=0, bias=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        n_points = x.shape[-1]\n",
    "\n",
    "        x = x.unsqueeze(-1)\n",
    "        x = x.repeat(1,1,1,n_points)\n",
    "        t = torch.transpose(x, 2, 3)\n",
    "        x = torch.cat((x, t), dim=1)\n",
    "\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        x = self.conv3(x)\n",
    "        x = self.bn3(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        x = self.conv4(x)\n",
    "        return x[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matching Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OptimalMatching(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(OptimalMatching, self).__init__()\n",
    "        \n",
    "        # Default configuration settings\n",
    "        self.descriptor_dim = 64\n",
    "        self.sinkhorn_iterations = 100\n",
    "        self.attention_layers = 4\n",
    "        self.correction_radius = 0.05\n",
    "\n",
    "        # Modules\n",
    "        self.scorenet1 = ScoreNet(self.descriptor_dim * 2)\n",
    "        self.scorenet2 = ScoreNet(self.descriptor_dim * 2)\n",
    "        self.gnn = AttentionalGNN(self.descriptor_dim, self.attention_layers)\n",
    "            \n",
    "\n",
    "    def normalize_coordinates(self, graph, ws, input):\n",
    "        if input == 'global':\n",
    "            graph = (graph * 2 / ws - 1)\n",
    "        elif input == 'normalized':\n",
    "            graph = ((graph + 1) * ws / 2)\n",
    "            graph = torch.round(graph).long()\n",
    "            graph[graph < 0] = 0\n",
    "            graph[graph >= ws] = ws - 1\n",
    "        return graph\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def log_optimal_transport_batch(self, Z, iters):\n",
    "        \"\"\"\n",
    "        Computes the optimal transport between all pairs of rows and columns of a batch of cost matrices Z in log space,\n",
    "        using the Sinkhorn algorithm.\n",
    "\n",
    "        Args:\n",
    "            Z: a tensor of shape (batch_size, m, n) representing a batch of cost matrices, where m is the number of rows\n",
    "            and n is the number of columns.\n",
    "            iters: the number of Sinkhorn iterations to perform.\n",
    "\n",
    "        Returns:\n",
    "            A tensor of the same shape as Z, containing the optimal transport plan between all pairs of rows and columns\n",
    "            in the batch.\n",
    "        \"\"\"\n",
    "        batch_size, m, n = Z.shape\n",
    "        log_mu = -torch.tensor(m).to(Z).log().expand(batch_size, m)\n",
    "        log_nu = -torch.tensor(n).to(Z).log().expand(batch_size, n)\n",
    "        u, v = torch.zeros_like(log_mu), torch.zeros_like(log_nu)\n",
    "\n",
    "        for _ in range(iters):\n",
    "            v = log_nu - torch.logsumexp(Z + u.unsqueeze(-1), dim=-2)\n",
    "            u = log_mu - torch.logsumexp(Z + v.unsqueeze(-2), dim=-1)\n",
    "\n",
    "        return Z + u.unsqueeze(-1) + v.unsqueeze(-2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def predict(self, image, descriptors, graph):\n",
    "        B, _, H, W = image.shape\n",
    "        B, N, _ = graph.shape\n",
    "\n",
    "        for b in range(B):\n",
    "            b_desc = descriptors[b]\n",
    "            b_graph = graph[b]\n",
    "\n",
    "            # Extract descriptors\n",
    "            b_desc = b_desc[:, b_graph[:,0], b_graph[:,1]]\n",
    "\n",
    "            # Concatenate descriptors in batches\n",
    "            if b == 0:                    \n",
    "                sel_desc = b_desc.unsqueeze(0)\n",
    "            else:\n",
    "                sel_desc = torch.cat((sel_desc, b_desc.unsqueeze(0)), dim=0)\n",
    "\n",
    "        # Multi-layer Transformer network. (Attentional Graph Neural Network)\n",
    "        norm_graph = self.normalize_coordinates(graph, W, input=\"global\") #out: normalized coordinate system [-1, 1]\n",
    "        sel_desc, offset = self.gnn(sel_desc, norm_graph)\n",
    "\n",
    "        # Correct points coordinates\n",
    "        norm_graph = norm_graph + offset * self.correction_radius\n",
    "        graph = self.normalize_coordinates(norm_graph, W, input=\"normalized\") # out: global coordinate system [0, W]\n",
    "\n",
    "        # Compute scores (Optimal connection Network)\n",
    "        scores_1 = self.scorenet1(sel_desc) # Clockwise Scores\n",
    "        scores_2 = self.scorenet2(sel_desc) # Counter-Clockwise Scores\n",
    "        scores = scores_1 + torch.transpose(scores_2, 1, 2) # Permutation Matrix\n",
    "\n",
    "        sinkhorn_scores = self.log_optimal_transport_batch(scores, self.sinkhorn_iterations)\n",
    "        \n",
    "        permutation_mat = scores_to_permutations(scores) # linear sum assignment\n",
    "        poly = permutations_to_polygons(permutation_mat, graph, out='torch') \n",
    "\n",
    "\n",
    "        return poly, permutation_mat, scores, sinkhorn_scores, graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy_loss(sinkhorn_results, gt_permutation):\n",
    "    loss_match = -torch.mean(torch.masked_select(sinkhorn_results, gt_permutation == 1))\n",
    "    return loss_match "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iou_loss_function(pred, gt):\n",
    "    B, H, W = gt.shape\n",
    "    total_iou = 0\n",
    "    \n",
    "    for batch in range(B):\n",
    "        batch_pred = torch.zeros((H, W), device=gt.device)\n",
    "        for poly in pred[batch]:\n",
    "            # Convert polygon to mask\n",
    "            mask = torch.zeros((H, W), device=gt.device)\n",
    "            poly_tensor = poly.long()  # Ensure integer coordinates\n",
    "            mask[poly_tensor[:, 1], poly_tensor[:, 0]] = 1\n",
    "            mask = F.max_pool2d(mask.unsqueeze(0).float(), kernel_size=3, stride=1, padding=1).squeeze(0)\n",
    "            batch_pred = torch.max(batch_pred, mask)\n",
    "        \n",
    "        plt.imshow(mask)\n",
    "        plt.show()\n",
    "        plt.imshow(gt[batch])\n",
    "        plt.show()\n",
    "        \n",
    "        intersection = torch.sum(torch.min(batch_pred, gt[batch]))\n",
    "        union = torch.sum(torch.max(batch_pred, gt[batch]))\n",
    "        batch_iou = intersection / (union + 1e-6)  # Add small epsilon to avoid division by zero\n",
    "        total_iou += batch_iou\n",
    "    \n",
    "    avg_iou = total_iou / B\n",
    "    return 1 - avg_iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iou_loss_function(pred, gt):\n",
    "    B, H, W = gt.shape\n",
    "    iou = 0\n",
    "    for batch in range(B):\n",
    "        K = len(pred[batch]) # Number of polygons\n",
    "        batch_tensor = np.zeros((K, H, W), dtype=np.uint8)\n",
    "        for i, poly in enumerate(pred[batch]):\n",
    "            cv2.fillPoly(batch_tensor[i], [poly.detach().cpu().numpy()], 1)\n",
    "\n",
    "        batch_pred_mask = torch.sum(torch.tensor(batch_tensor), dim=0).permute(1,0)\n",
    "\n",
    "        # plt.imshow(batch_pred_mask)\n",
    "        # plt.show()\n",
    "        # plt.imshow(gt[batch])\n",
    "        # plt.show()\n",
    "\n",
    "        intersection = torch.min(batch_pred_mask, gt[batch])\n",
    "        union = torch.max(batch_pred_mask, gt[batch])\n",
    "        batch_iou = torch.sum(intersection) / torch.sum(union)\n",
    "        iou += batch_iou\n",
    "\n",
    "    return torch.tensor(1 - iou, requires_grad=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Backbone\n",
    "model = R2U_Net()\n",
    "model = model.to(device)\n",
    "model = model.train()\n",
    "model.load_state_dict(torch.load('trained_weights/polyworld_backbone', map_location=device))\n",
    "\n",
    "# Vertex Detection\n",
    "head_ver = DetectionBranch()\n",
    "head_ver = head_ver.to(device)\n",
    "head_ver = head_ver.train()\n",
    "head_ver.load_state_dict(torch.load('trained_weights/polyworld_seg_head', map_location=device))\n",
    "\n",
    "# NMS\n",
    "suppression = NonMaxSuppression()\n",
    "suppression = suppression.to(device)\n",
    "\n",
    "# Matching\n",
    "matching = OptimalMatching()\n",
    "matching = matching.to(device)\n",
    "matching = matching.train()\n",
    "matching.load_state_dict(torch.load('trained_weights/polyworld_matching', map_location=device))\n",
    "\n",
    "# Freeze \n",
    "# for param in model.parameters():\n",
    "#     param.requires_grad = False\n",
    "\n",
    "# for param in head_ver.parameters():\n",
    "#     param.requires_grad = False\n",
    "\n",
    "# for param in matching.parameters():\n",
    "#     param.requires_grad = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph_to_vertex_mask(points, image):\n",
    "    B, _, H, W = image.shape\n",
    "\n",
    "    mask = torch.zeros((B, H, W), dtype=torch.uint8)\n",
    "\n",
    "    # Loop style\n",
    "    # for batch in range(B):\n",
    "    #     mask[batch, points[batch, :, 0], points[batch, :, 1]] = 1\n",
    "\n",
    "    # Vectorized Style\n",
    "    batch_indices = np.arange(B)[:, None]\n",
    "    mask[batch_indices, points[:, :, 0], points[:, :, 1]] = 1\n",
    "    \n",
    "    return mask\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def polygon_to_vertex_mask(polygons: list):\n",
    "    B = len(polygons)\n",
    "    mask = torch.zeros((B, 320, 320), dtype=torch.uint8)\n",
    "\n",
    "    for batch in range(B):\n",
    "        batch_polygons = [np.array(poly, dtype=int) for poly in polygons[batch]]\n",
    "        for poly in batch_polygons:\n",
    "            for point in poly:\n",
    "                mask[batch, point[1], point[0]] = 1\n",
    "\n",
    "\n",
    "    return mask\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def tensor_to_numpy(input: list):\n",
    "    ''' convert a list of tensors to a list of numpy arrays '''\n",
    "    numpy = []\n",
    "    for batch in range(len(input)):\n",
    "        batch_polygons = [tensor.cpu().numpy() for tensor in input[batch]]\n",
    "        numpy.append(batch_polygons)\n",
    "    return numpy\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def point_to_polygon(points: list):\n",
    "    \n",
    "    B = len(points)\n",
    "    polygons = []\n",
    "\n",
    "    for batch in range(B):\n",
    "        batch_polygons = [np.array(poly, dtype=int).reshape(-1, 2) for poly in points[batch]]\n",
    "        polygons.append(batch_polygons)\n",
    "\n",
    "    return polygons\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def polygon_to_seg_mask():\n",
    "    pass\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def point_to_permutation():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer\n",
    "optimizer = torch.optim.Adam([\n",
    "    # {'params': model.parameters()},\n",
    "    # {'params': head_ver.parameters()},\n",
    "    {'params': matching.parameters()}\n",
    "], lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = 100\n",
    "# detection_loss_function = nn.BCELoss(weight=torch.tensor([w])).to(device) # For Vertices # Cuda Error using this loss!\n",
    "# detection_loss_function = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([w])).to(device) # For Vertices\n",
    "\n",
    "# matching_loss_function = nn.CrossEntropyLoss().to(device)  # For Permutation Matrix\n",
    "# matching_loss_function = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([w])).to(device)\n",
    "# matching_loss_function = nn.NLLLoss().to(device)\n",
    "# matching_loss_function = nn.BCELoss().to(device)\n",
    "\n",
    "# angle_loss_function = AngleLoss().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(dataset, batch_size=2, shuffle=False, num_workers=4, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Loop\n",
    "EPOCHS = 300\n",
    "for epoch in range(EPOCHS):\n",
    "    for image, gt_vertex_mask, gt_seg_mask, gt_permutation_matrix, gt_polygons in tqdm(dataloader):\n",
    "\n",
    "        # Stack Tensors\n",
    "        image, gt_vertex_mask, gt_seg_mask, gt_permutation_matrix = torch.stack(image), torch.stack(gt_vertex_mask), torch.stack(gt_seg_mask), torch.stack(gt_permutation_matrix)\n",
    "\n",
    "        # Move Inputs to Device\n",
    "        image = image.float().permute(0, 3, 1, 2).to(device)\n",
    "        gt_vertex_mask = gt_vertex_mask.unsqueeze(1).to(device)\n",
    "        # gt_seg_mask = gt_seg_mask.unsqueeze(1).cuda()\n",
    "        gt_permutation_matrix = gt_permutation_matrix.float().to(device)\n",
    "        # gt_polygons = gt_polygons.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        features = model(image)\n",
    "        vertex_logits = head_ver(features) # occupancy grid\n",
    "        _ , graph = suppression(vertex_logits) # (B, 256, 2) --> Vertex Positions\n",
    "        poly, permutation_matrix, scores, sinkhorn_scores, _ = matching.predict(image, features, graph) # Graph --> Vertex Points | features --> descriptors\n",
    "        # permutation_matrix = permutation_matrix.to(device)\n",
    "        # permutation_matrix.requires_grad = True\n",
    "\n",
    "\n",
    "        # del features\n",
    "        # del vertex_logits\n",
    "        # del graph\n",
    "        del image\n",
    "        # del gt_vertex_mask\n",
    "        # del gt_seg_mask\n",
    "        # del gt_permutation_matrix\n",
    "        # del gt_polygons\n",
    "\n",
    "        # print('Graph: ', graph.shape)\n",
    "        # print('Permutation Matrix: ', permutation_matrix.shape)\n",
    "        # print('Poly: ', len(poly))\n",
    "        # print('Scores: ', scores.shape)\n",
    "        # print('Vertex Logits: ', vertex_logits.shape)\n",
    "        # print('Features: ', features.shape)\n",
    "        # print('GT Vertex Mask: ', gt_vertex_mask.shape)\n",
    "        # print('GT Seg Mask: ', gt_seg_mask.shape)\n",
    "        # print('GT Permutation Matrix: ', gt_permutation_matrix.shape)\n",
    "        # print('GT Polygons: ', len(gt_polygons))\n",
    "\n",
    "\n",
    "        # Compute loss\n",
    "        # detection_loss = detection_loss_function(vertex_logits, gt_vertex_mask.float())\n",
    "        # segmentation_loss = iou_loss_function(poly, gt_seg_mask)\n",
    "        # matching_loss = matching_loss_function(permutation_matrix.float(), gt_permutation_matrix)\n",
    "        matching_loss = cross_entropy_loss(sinkhorn_scores, gt_permutation_matrix)\n",
    "\n",
    "\n",
    "\n",
    "        loss = matching_loss\n",
    "\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "        # del image, gt_vertex_mask, gt_seg_mask, gt_permutation_matrix, features, vertex_logits, graph, poly\n",
    "\n",
    "\n",
    "    # plt.imshow(vertex_logits[0].detach().cpu().numpy().squeeze())\n",
    "    # plt.show()\n",
    "    plt.imshow(permutation_matrix[0].detach().cpu().numpy())\n",
    "    plt.show()\n",
    "    plt.imshow(gt_permutation_matrix[0].detach().cpu().numpy())\n",
    "    plt.show()\n",
    "    # plt.imshow(scores[0].detach().cpu().numpy())    \n",
    "    # plt.show()\n",
    "\n",
    "    \n",
    "    # print('Detection Loss: ', detection_loss)\n",
    "    # print('Segmentation Loss: ', segmentation_loss)\n",
    "    print('Matching Loss: ', matching_loss)\n",
    "    print(f\"Epoch {epoch} - Loss: {loss.item()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the complete model and optimizer state\n",
    "torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss': loss,\n",
    "            }, 'trained_weights/polyworld_backbone_overfit_1sample.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inputs\n",
    "image, gt_vertex_mask, gt_seg_mask, gt_permutation_matrix, gt_polygons = next(iter(dataloader))\n",
    "image, gt_vertex_mask, gt_seg_mask, gt_permutation_matrix = torch.stack(image), torch.stack(gt_vertex_mask), torch.stack(gt_seg_mask), torch.stack(gt_permutation_matrix)\n",
    "image = image.float().cuda().permute(0, 3, 1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Image: ', image.shape)\n",
    "print('Vertex: ', gt_vertex_mask.shape)\n",
    "print('Segmentation: ', gt_seg_mask.shape)\n",
    "print('Permutation: ', gt_permutation_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outputs\n",
    "features = model(image)\n",
    "vertex_logits = head_ver(features)\n",
    "_ , graph = suppression(vertex_logits)\n",
    "poly, permutation_matrix, scores, sinkhorn_scores, graph_refined = matching.predict(image, features, graph) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('RGB: ', image.shape)\n",
    "print('Features Map: ', features.shape)\n",
    "print('Vertex Logits: ', vertex_logits.shape)\n",
    "print('Graph: ', graph.shape)\n",
    "print('Permutation Matrix: ', permutation_matrix.shape)\n",
    "print('Sinkhorn Scores: ', sinkhorn_scores.shape)\n",
    "print('Scores: ', scores.shape)\n",
    "print('Graph Refined: ', graph_refined.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(image[0].permute(1,2,0).cpu().numpy())\n",
    "plt.imshow(vertex_logits[0].cpu().detach().numpy().squeeze(), alpha=.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(20, 10))\n",
    "\n",
    "axes[0].imshow(torch.sigmoid(scores[0]).cpu().detach().numpy())\n",
    "axes[0].set_title(\"Scores\")\n",
    "\n",
    "axes[1].imshow(torch.sigmoid(sinkhorn_scores[0]).cpu().detach().numpy())\n",
    "axes[1].set_title(\"Sinkhorn Scores\")\n",
    "\n",
    "\n",
    "\n",
    "# plt.imshow(torch.sigmoid(scores[0]).cpu().detach().numpy())\n",
    "# plt.imshow(torch.sigmoid(sinkhorn_scores[0]).cpu().detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(torch.sigmoid(sinkhorn_scores[0]).cpu().detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(20, 10))\n",
    "\n",
    "axes[0].imshow(sinkhorn_scores[i].detach().cpu().numpy())\n",
    "axes[0].set_title(\"Sinkhorn Scores\")\n",
    "\n",
    "axes[1].imshow(permutation_matrix[i].detach().cpu().numpy())\n",
    "axes[1].set_title(\"Permutation Matrix\")\n",
    "\n",
    "axes[2].imshow(scores[i].detach().cpu().numpy())\n",
    "axes[2].set_title(\"Scores\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask1 = graph_to_vertex_mask(graph, image)\n",
    "\n",
    "mask2 = polygon_to_vertex_mask(tensor_to_numpy(poly)).permute(0, 2, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(mask2[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask1.shape, mask2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot mask and seg mask\n",
    "i = 0\n",
    "fig, axes = plt.subplots(1, 4, figsize=(21, 13))\n",
    "axes[0].imshow(gt_vertex_mask[i].cpu().numpy().squeeze())\n",
    "axes[1].imshow(mask1[i])\n",
    "axes[2].imshow(mask2[i])\n",
    "axes[3].imshow(gt_seg_mask[i].cpu().numpy().squeeze())\n",
    "\n",
    "\n",
    "axes[0].set_title('GT Vertex Mask')\n",
    "axes[1].set_title('Prediction after NMS')\n",
    "axes[2].set_title('Prediction from Permutations Matrix + Graph')\n",
    "axes[3].set_title('GT Segmentation Mask')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(21, 13))\n",
    "\n",
    "axes[0].imshow(gt_permutation_matrix[i].cpu().numpy())\n",
    "axes[1].imshow(permutation_matrix[i].cpu().numpy())\n",
    "\n",
    "axes[0].set_title('GT Permutation Matrix')\n",
    "axes[1].set_title('Prediction Permutation Matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply sigmoid to the logits\n",
    "output = torch.sigmoid(vertex_logits)\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(21, 13))\n",
    "axes[0].imshow(output[i].detach().cpu().numpy().squeeze())\n",
    "axes[1].imshow(vertex_logits[i].detach().cpu().numpy().squeeze())\n",
    "axes[2].imshow(image[i].cpu().numpy().squeeze().transpose(1, 2, 0))\n",
    "\n",
    "axes[0].set_title('Applied Sigmoid on Logits')\n",
    "axes[1].set_title('Logits')\n",
    "axes[2].set_title('RGB Image')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bounding_box_from_points(points):\n",
    "    points = np.array(points).flatten()\n",
    "    even_locations = np.arange(points.shape[0]/2) * 2\n",
    "    odd_locations = even_locations + 1\n",
    "    X = np.take(points, even_locations.tolist())\n",
    "    Y = np.take(points, odd_locations.tolist())\n",
    "    bbox = [X.min(), Y.min(), X.max()-X.min(), Y.max()-Y.min()]\n",
    "    bbox = [int(b) for b in bbox]\n",
    "    return bbox\n",
    "\n",
    "\n",
    "def single_annotation(image_id, poly):\n",
    "    _result = {}\n",
    "    _result[\"image_id\"] = int(image_id)\n",
    "    _result[\"category_id\"] = 100 \n",
    "    _result[\"score\"] = 1\n",
    "    _result[\"segmentation\"] = poly\n",
    "    _result[\"bbox\"] = bounding_box_from_points(_result[\"segmentation\"])\n",
    "    return _result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(batch_size, images_directory, annotations_path):\n",
    "\n",
    "    # Vertex Detection\n",
    "    model = R2U_Net()\n",
    "    model = model.cuda()\n",
    "    model = model.train()\n",
    "\n",
    "    head_ver = DetectionBranch()\n",
    "    head_ver = head_ver.cuda()\n",
    "    head_ver = head_ver.train()\n",
    "\n",
    "\n",
    "    # NMS\n",
    "    suppression = NonMaxSuppression()\n",
    "    suppression = suppression.cuda()\n",
    "\n",
    "    # Generate the connections between virtices\n",
    "    matching = OptimalMatching()\n",
    "    matching = matching.cuda()\n",
    "    matching = matching.train()\n",
    "\n",
    "    # NOTE: The modules are set to .train() mode during inference to make sure that the BatchNorm layers \n",
    "    # rely on batch statistics rather than the mean and variance estimated during training. \n",
    "    # Experimentally, using batch stats makes the network perform better during inference.\n",
    "\n",
    "    print(\"Loading pretrained model\")\n",
    "    model.load_state_dict(torch.load(\"./trained_weights/polyworld_backbone\"))\n",
    "    head_ver.load_state_dict(torch.load(\"./trained_weights/polyworld_seg_head\"))\n",
    "    matching.load_state_dict(torch.load(\"./trained_weights/polyworld_matching\"))\n",
    "\n",
    "    # Initiate the dataloader\n",
    "    CrowdAI_dataset = CrowdAI(images_directory=images_directory, annotations_path=annotations_path)\n",
    "    dataloader = DataLoader(CrowdAI_dataset, batch_size=batch_size, shuffle=False, num_workers=batch_size)\n",
    "\n",
    "    train_iterator = tqdm(dataloader)\n",
    "\n",
    "    speed = []\n",
    "    predictions = []\n",
    "    for i_batch, sample_batched in enumerate(train_iterator):\n",
    "\n",
    "        rgb = sample_batched['image'].cuda().float()\n",
    "        idx = sample_batched['image_idx']\n",
    "\n",
    "        t0 = time.time()\n",
    "\n",
    "        features = model(rgb)\n",
    "        occupancy_grid = head_ver(features)\n",
    "\n",
    "        _, graph_pressed = suppression(occupancy_grid)\n",
    "\n",
    "        poly = matching.predict(rgb, features, graph_pressed) \n",
    "\n",
    "        speed.append(time.time() - t0)\n",
    "\n",
    "\n",
    "        for i, pp in enumerate(poly):\n",
    "            for p in pp:\n",
    "                predictions.append(single_annotation(idx[i], [p]))\n",
    "\n",
    "        del features\n",
    "        del occupancy_grid\n",
    "        del graph_pressed\n",
    "        del poly\n",
    "        del rgb\n",
    "        del idx\n",
    "\n",
    "    print(\"Average model speed: \", np.mean(speed) / batch_size, \" [s / image]\")\n",
    "\n",
    "    # fp = open(\"predictions.json\", \"w\")\n",
    "    # fp.write(json.dumps(predictions))\n",
    "    # fp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction(batch_size=1, images_directory=\"data/val/images/\", annotations_path=\"data/val/annotation.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Playground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/val/annotation.json') as f:\n",
    "    annotations = json.load(f)\n",
    "\n",
    "images = pd.DataFrame(annotations['images'])\n",
    "labels = pd.DataFrame(annotations['annotations'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segmentations = labels[labels['image_id'] == 9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segmentations = segmentations['segmentation'].values\n",
    "segmentations = [e[0] for e in segmentations]\n",
    "segmentations = [np.array(poly, dtype=int).reshape(-1, 2) for poly in segmentations]\n",
    "# segmentations = [np.array(poly * ratio, dtype=int).reshape(-1, 2) for poly in segmentations]\n",
    "segmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "N = 256\n",
    "permutation_matrix = np.zeros((N, N))\n",
    "\n",
    "n = 0\n",
    "for i, polygon in enumerate(segmentations):\n",
    "    for v, point in enumerate(polygon):\n",
    "        if v != len(polygon) - 1:\n",
    "            permutation_matrix[n, n+1] = 1\n",
    "        else:\n",
    "            permutation_matrix[n, n-v] = 1\n",
    "        n += 1\n",
    "    \n",
    "    print(f'Polygon {i} Finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 15))\n",
    "plt.imshow(permutation_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(segmentations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_adjacency_matrix(polygons, N=256):\n",
    "    # Initialize the permutation matrix\n",
    "    permutation_matrix = np.zeros((N, N), dtype=int)\n",
    "    \n",
    "    for polygon in polygons:\n",
    "        # Extract vertices from the polygon list\n",
    "        vertices = [(polygon[i], polygon[i+1]) for i in range(0, len(polygon), 2)]\n",
    "        \n",
    "        # Get the number of vertices\n",
    "        num_vertices = len(vertices)\n",
    "        \n",
    "        for i in range(num_vertices):\n",
    "            # Current vertex\n",
    "            current_vertex = vertices[i]\n",
    "            # Next vertex (with wrap-around)\n",
    "            next_vertex = vertices[(i + 1) % num_vertices]\n",
    "            \n",
    "            # Find indices of current and next vertices\n",
    "            current_index = i\n",
    "            next_index = (i + 1) % num_vertices\n",
    "            \n",
    "            # Update the permutation matrix\n",
    "            permutation_matrix[current_index, next_index] = 1\n",
    "            # permutation_matrix[next_index, current_index] = 1\n",
    "    \n",
    "    return permutation_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_matrix = create_adjacency_matrix(segmentations, N=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(adj_matrix[:20, :20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_optimal_transport_batch(Z, iters):\n",
    "    \"\"\"\n",
    "    Computes the optimal transport between all pairs of rows and columns of a batch of cost matrices Z in log space,\n",
    "    using the Sinkhorn algorithm.\n",
    "\n",
    "    Args:\n",
    "        Z: a tensor of shape (batch_size, m, n) representing a batch of cost matrices, where m is the number of rows\n",
    "        and n is the number of columns.\n",
    "        iters: the number of Sinkhorn iterations to perform.\n",
    "\n",
    "    Returns:\n",
    "        A tensor of the same shape as Z, containing the optimal transport plan between all pairs of rows and columns\n",
    "        in the batch.\n",
    "    \"\"\"\n",
    "    batch_size, m, n = Z.shape\n",
    "    log_mu = -torch.tensor(m).to(Z).log().expand(batch_size, m)\n",
    "    log_nu = -torch.tensor(n).to(Z).log().expand(batch_size, n)\n",
    "    u, v = torch.zeros_like(log_mu), torch.zeros_like(log_nu)\n",
    "\n",
    "    for _ in range(iters):\n",
    "        v = log_nu - torch.logsumexp(Z + u.unsqueeze(-1), dim=-2)\n",
    "        u = log_mu - torch.logsumexp(Z + v.unsqueeze(-2), dim=-1)\n",
    "\n",
    "    return Z , u.unsqueeze(-1) , v.unsqueeze(-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a (8, 10, 10) torch tensor with value 1 at random indices\n",
    "Z = torch.zeros((8, 10, 10))\n",
    "for i in range(8):\n",
    "    idx = torch.randint(0, 10, (10, 2))\n",
    "    Z[i, idx[:, 0], idx[:, 1]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(Z[0].detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z, u, v = log_optimal_transport_batch(Z, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v.shape, u.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(Z[0].detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(u[0].detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(v[0].detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = u[0] + v[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "poly",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
